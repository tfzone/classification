# [classification](https://github.com/tfzoo/classification) 
[![sites](tfzoo/tfzoo.png)](http://www.tfzoo.com)
#### qitas@qitas.cn
### [简介](https://github.com/tfzoo/classification/wiki) 

分类是一个有监督的学习过程，目标数据库中有哪些类别是已知的，分类过程需要做的就是把每一条记录归到对应的类别之中。由于必须事先知道各个类别的信息，并且所有待分类的数据条目都默认有对应的类别，因此分类算法也有其局限性，当上述条件无法满足时，我们就需要尝试聚类分析。

### [参考](tfzoo/) 

#### [KNN](https://github.com/markdregan/K-Nearest-Neighbors-with-Dynamic-Time-Warping) 

KNN(K Nearest Neighbor)是通过测量不同特征值之间的距离进行分类。它的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别，其中K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。KNN算法的结果很大程度取决于K的选择。

#### [Naive Bayes](https://github.com/jbrukh/bayesian) 

贝叶斯分类算法是统计分类算法的一种，他是一类利用概率统计知识进行的一种分类算法。而朴素贝叶斯算法就是里面贝叶斯算法中最简单的一个算法。为什么叫做朴素贝叶斯，因为他里面的各个类条件是独立的，所以一会在后面的计算中会起到很多方便的作用。

朴素贝叶斯的思想基础是这样的：对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。通俗来说，就好比这么个道理，你在街上看到一个黑人，我问你你猜这哥们哪里来的，你十有八九猜非洲。为什么呢？因为黑人中非洲人的比率最高，当然人家也可能是美洲人或亚洲人，但在没有其它可用信息下，我们会选择条件概率最大的类别，这就是朴素贝叶斯的思想基础。

该算法用到的一个核心概率公式: P(B|A) = (P(A|B)P(B))/P(A) ，从这个公式可以看到贝叶斯的巨大作用就是对因果关系进行了交换。

分类流程如下： 
- 准备阶段：确定特征属性，或缺训练样本。 
- 分类器训练阶段：对每个类别计算P(yi)，对每个特征属性计算所有划分的条件概率； 
- 应用阶段：对每个类别计算P(x|yi)p(yi)，以P(x|yi)p(yi)最大项作为x所属类别。

#### [decision tree](https://github.com/igrigorik/decisiontree) 

决策树（decision tree）：是一种基本的分类与回归方法，此处主要讨论分类的决策树。

在分类问题中，表示基于特征对实例进行分类的过程，可以认为是if-then的集合，也可以认为是定义在特征空间与类空间上的条件概率分布。

决策树通常有三个步骤：特征选择、决策树的生成、决策树的修剪。

用决策树分类：从根节点开始，对实例的某一特征进行测试，根据测试结果将实例分配到其子节点，此时每个子节点对应着该特征的一个取值，如此递归的对实例进行测试并分配，直到到达叶节点，最后将实例分到叶节点的类中。

###  www.tfzoo.com
